{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"regresion_ls_ejercicios.ipynb","provenance":[],"collapsed_sections":[],"toc_visible":true,"authorship_tag":"ABX9TyOtZDXHi7BNMnWif/uyryXu"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["<a href=\"https://colab.research.google.com/github/institutohumai/cursos-python/blob/master/MachineLearning/1_Introduccion/Ejercicios/regresion_ls_ejercicios.ipynb\"> <img src='https://colab.research.google.com/assets/colab-badge.svg' /> </a>"],"metadata":{"id":"HtxYCjX4w6t5"}},{"cell_type":"markdown","source":["# Prediciendo ventas de productos\n","\n","En este ejercicio continuaremos viendo el dataset visto en la notebook anterior. Queremos predecir las ventas del producto y nuestro conjunto de datos tiene las ventas en 200 mercados, y el presupuesto dedicado en publicidad en 3 medios: TV, radio y diario.\n","\n","Carguemos este dataset y algunas librerías:"],"metadata":{"id":"nTORVO-lwqQN"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"ilh4zsmcvsFK"},"outputs":[],"source":["import pandas as pd\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import statsmodels.api as sm\n","import seaborn as sns; sns.set()"]},{"cell_type":"code","source":["df = pd.read_csv('https://datasets-humai.s3.amazonaws.com/datasets/advertising.csv')"],"metadata":{"id":"USR-jTAYZGcW"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Como habiamos visto antes la relación parece ser lineal con la variable TV, es decir cuanta plata se invirtió ahí. Crear un `X` dataframe que tenga solo las variables TV, Radio y Newspaper, y crear una variable `y` que tenga solo el dato de las ventas."],"metadata":{"id":"kWWoHD24xfMQ"}},{"cell_type":"code","source":["# Completar\n","X = ...\n","y = ..."],"metadata":{"id":"pDsTqF60xeiW"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Ejercicio 1 - Train Test Split\n","\n","a) En este ejericio elaborar una separación de datos en entrenamiento, dejando un 25% de datos para prueba. Para eso utilicen `train_test_split` de Scikit-Learn basandose en el ejemplo presente en la [documentación](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html), deberían crear una variable `X_train`, `X_test`, con los features, y con los targets `y_train`, e `y_test`. ¿Qué tamaño tiene cada conjunto? ¿El conjunto que crearon tiene el mismo orden de filas?\n"],"metadata":{"id":"_yg1LtRexl_x"}},{"cell_type":"code","source":["from sklearn.model_selection import train_test_split\n","\n","# Completar\n","..."],"metadata":{"id":"k7TjRDZYyf9O"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["b) Quedarse solo con la columna que corresponde a TV, y ajustar un modelo de regresion lineal al conjunto de entrenamiento con intercept. Tambien construir una matriz que tenga solo la columna de TV en el conjunto de test. "],"metadata":{"id":"F4xtbz8a0x5M"}},{"cell_type":"code","source":["from sklearn.linear_model import LinearRegression\n","\n","# Completar\n","X_train_tv = ...\n","X_test_tv  = ...\n","\n","..."],"metadata":{"id":"6wLIeb-U1ffP"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["c) Ahora vamos a querer evaluar nuestro modelo en nuestro conjunto de testeo, para eso tenemos que calcular las predicciones del modelo $\\hat{y}$, y para esto usamos el método `predict` sobre todo el conjunto de testeo.\n","\n","`y_predicted = modelo.predict(X_test)`\n","\n","Luego, usando los valores reales de `y` en el conjunto de test, nos interesa calcular el error de nuestro modelo en datos que no vio, justamente el conjunto de test. Para eso vamos a calcular uno de los errores más populares, el [Error Cuadrático Medio](https://es.wikipedia.org/wiki/Error_cuadr%C3%A1tico_medio):\n","\n","$ ECM = \\dfrac{1}{n} \\sum (y_i - \\hat{y}_i)^2$\n","\n","Es decir que el ECM es el promedio de la diferencia entre los vectores `y_test` e `y_predict` elevadas al cuadrado. Calcular el ECM usando solo herramientas de `numpy`:"],"metadata":{"id":"I6epDgvv1qF7"}},{"cell_type":"code","source":["# Completar\n","\n","# calculamos las predicciones sobre test\n","y_predict = ...\n","\n","# calculamos el cuadrado de las diferencias de estos vectores\n","ecm = ...\n","\n","# calculamos el promedio usando mean\n","print('El ECM fue de: ', ecm.mean())"],"metadata":{"id":"r7qpBxyX1quB"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["d) Podemos usar el ECM que nos brinda SkLearn: [RMS](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.mean_squared_error.html?highlight=rms). Calcularlo el ECM para cada conjunto, entrenamiento y testo. ¿En que conjunto rindió mejor nuestro modelo?"],"metadata":{"id":"GIbJK_Ka29hK"}},{"cell_type":"code","source":["from sklearn.metrics import mean_squared_error\n","\n","# Completar (debería dar lo mismo que el item anterior)\n","..."],"metadata":{"id":"E0HV-ZiH7I04"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Ejercicio 2 - Probando otras variables\n","\n","Ajustar un modelo lineal para cada variable sobre el conjunto que entrenamiento y calcular el error sobre cada conjunto para cada modelo. Comparar el rendimiento de cada modelo en ambos conjuntos, ¿cuál fue el mejor modelo?. Por lo visto en clase, ¿era esperable este resultado?"],"metadata":{"id":"rLhkpva20gBr"}},{"cell_type":"code","source":["from sklearn.metrics import mean_squared_error\n","\n","# Completar\n","\n","# sugerencia (pueden no usarla)\n","def regresion_ls(X_train:pd.DataFrame, \n","                 X_test :pd.DataFrame,\n","                 y_train:pd.Series, \n","                 y_test :pd.Series,\n","                 var: str):\n","  \"\"\"\n","  Input\n","    X, y: Datos\n","    var: Nombre del feature a utilizar para ajustar un modelo de regresion simple\n","  Output\n","    El modelo y métrica\n","  \"\"\"\n","  ...\n","  \n","  return modelo\n","\n","..."],"metadata":{"id":"hMsoUOCJ601-"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["¿Cuál es el peso asignado a cada variable por nuestros modelos? ¿Utilizaría solo este dato para hacer una recomendación sobre donde invertir de los tres medios?"],"metadata":{"id":"AM2gOKfd9JKY"}},{"cell_type":"code","source":["# Completar\n","..."],"metadata":{"id":"Wn1mBdUA9G5E"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Haciendo regresiones en conjuntos de juguete\n","\n","Scikit-Learn es una librería muy versátil que nos brinda herramientas no solo relacionados a los tipos de modelos, sino que tambíen nos deja crear datasets de juguete según la tarea que nos interese, en este caso la regresión. Para eso contamos con la función [`make_regresion`](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.make_regression.html#sklearn.datasets.make_regression), donde no solo obtenemos las features y los targets, sino que también nos devuelve el coeficiente utilizado para generar este conjunto. "],"metadata":{"id":"mTz1eJgw2n8K"}},{"cell_type":"code","source":["from sklearn.datasets import make_regression\n","from sklearn.model_selection import train_test_split\n","\n","# Ejemplo\n","n_samples_train, n_samples_test, n_features = 4000, 1000, 1\n","\n","X, y, coef = make_regression(\n","    n_samples=n_samples_train + n_samples_test,\n","    n_features=n_features,\n","    n_informative=1,\n","    shuffle=False,\n","    noise=10.0,\n","    coef=True,\n","    bias = -7,\n","    random_state = 2022\n",")\n","\n","plt.scatter(X,y);\n","print(coef)"],"metadata":{"id":"19bqwWBrA8vX"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Esto nos crea un dataset donde con la cantidad de muestras solicitadas, la cantidad de features, pudiendo controlar el ruido que se utiliza para generar estas instancias. Vamos a utilizar este dataset para evaluar nuestros modelos de regresión, aprovechando que sabemos el *coeficiente* que se utilizó para generar los datos."],"metadata":{"id":"pF8SSslTPb1g"}},{"cell_type":"markdown","source":["## Ejercicio 1 - Toy Dataset\n","\n","A partir del X e y creados anteriormente, seleccione los últimos 1000 datos para el conjunto de testeo y los primeros 4000 para entrenamiento. Ajuste un modelo lineal con intercept y reporte el *error cuadrático* tanto en entrenamiento como en test. Reporten el error cuadrático en test."],"metadata":{"id":"1QWS1iuC75Vt"}},{"cell_type":"code","source":["# Completar\n","X_train = ...\n","y_train = ...\n","X_test = ...\n","y_test = ...\n","\n","..."],"metadata":{"id":"PuFRMyfH745h"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["¿Qué tan parecidos quedaron los coeficientes de nuestro modelo en comparación de los que se usaron para generar nuestro dataset?"],"metadata":{"id":"GUBpLmcIYXm9"}},{"cell_type":"code","source":["# Completar\n","..."],"metadata":{"id":"aWS93JkPYIe9"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Graficar los datos junto a nuestro modelo. "],"metadata":{"id":"7XHUMrOoYmgp"}},{"cell_type":"code","source":["# Completar\n","\n","# para graficar la recta\n","xfit = np.linspace(-4, 4, 1000)\n","yfit = ...\n","\n","plt.scatter(X_train, y_train, label = 'train')\n","plt.scatter(X_test, y_test, label = 'test')\n","plt.plot(xfit, yfit, 'r', label = 'modelo');\n","plt.legend();"],"metadata":{"id":"6tP5nZKAYmLS"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Ejercicio 2 - Comparando nuestros modelos con $R^2$\n","\n","$R^2$ es una métrica que nos permite evaluar cuanta variabilidad del conjunto original de datos camptura nuestro modelo. Se lo conoce también como el [*coeficiente de determinación*](https://es.wikipedia.org/wiki/Coeficiente_de_determinaci%C3%B3n), y sklearn tiene su [implementación](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.r2_score.html?highlight=r2#sklearn.metrics.r2_score). A diferencia del ECM, no se trata de una función de error, que mide que tan lejos esta nuestro modelo de los datos reales (errores más chicos es mejor), sino de un *score* o puntaje, es decir que más grande es mejor y lo máximo que pude valer es 1.\n","\n","$ R^2 = 1 - \\frac{\\text{variación no explicada}}{\\text{variación total}} = 1 - \\dfrac{(\\sum y_i - \\hat{y}_i)^2}{(\\sum y_i - \\bar{y})^2}$\n","\n","\n","Calcular el valor de $R^2$ para nuestro modelo:"],"metadata":{"id":"p8CKHtzW0oAr"}},{"cell_type":"code","source":["from sklearn.metrics import r2_score\n","\n","# Completar\n","r2 = ...\n","print(r2)"],"metadata":{"id":"KeFCAfFT1LGy"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Ejercicio 3 - Efecto del conjunto de entrenamiento: Learning Curves\n","\n","Muchas veces escucharemos aseverar que tener más datos es mejor, pero eso no es necesariamente cierto. Para ver si nuestro modelo necesita mas datos para mejorar su rendimiento podemos armar lo que se conoce como *curvas de aprendizaje* o *Learning curves*.\n","\n","Básicamente lo que haremos es empezar de un conjunto de entrenamiento muy pequeño e iremos incrementando la cantidad de datos del mismo, para ver si el rendimiento de cada modelo mejor o no al incorporar más datos. Scikit Learn nos provee una [función](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.learning_curve.html#sklearn.model_selection.learning_curve) para hacerlo, sin embargo vamos a hacer algo similar pero de manera manual.\n","\n","Completar el código siguiente para calcular un modelo para cada subconjunto de entrenamiento considerado, en el cual nos iremos quedando con distintos porcentajes de entrenamiento desde el 5% al 100%. Guardarse los $R^2$ en entrenamiento y testeo para cada modelo y finalmente realizar un gráfico donde veamos el error en función del porcentaje total de datos usado."],"metadata":{"id":"5DoQn-R38Cbu"}},{"cell_type":"code","source":["# Completar - \n","\n","train_errs = []\n","test_errs  = []\n","\n","...\n","\n","plt.plot(np.linspace(0.05,1,20), train_errs)\n","plt.plot(np.linspace(0.05,1,20), test_errs)\n","plt.legend(['train', 'test']);"],"metadata":{"id":"tQRHyAt28BrQ"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Vemos finalmente que nuestro modelo mejora con más datos de entrenamiento su rendimiento en entrenamiento, como era esperable. Sin embargo, satura rapidamente el rendimiento en test.\n","\n","*Aclaración*: Lo que acabamos de hacer no es exactamente una curva de aprendizaje, ya que deberiamos, para cada percentil, poder ajustar muchos conjuntos aleatorio con esa cantida de casos. Esto al menos nos garantizará poder estimar los desvíos para poder tener mayor rigurosidad estadística.\n","\n","Para más detalles analizar este [ejemplo](https://scikit-learn.org/stable/auto_examples/model_selection/plot_learning_curve.html)."],"metadata":{"id":"9KmQ8tyIWFxg"}}]}