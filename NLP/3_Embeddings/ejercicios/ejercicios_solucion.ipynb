{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "colab": {
      "name": "ejercicios_solucion.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "8gc419sbFyhp",
        "wALYs4TxFyhs",
        "H_pZbD8KIEbE",
        "N-LPUGIHIQdz",
        "eJygipMmRkWc",
        "rP1P0JZdggBA",
        "K5-x66lDghoP",
        "uRiYnNxpglif",
        "Ul_5J7R_Fyh-",
        "HSzBc_zfFvaQ",
        "xUae6yInGj9K",
        "F9u69MfxFvbv",
        "Sw7PyzY3Gcup"
      ]
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "<a href=\"https://colab.research.google.com/github/institutohumai/cursos-python/blob/master/NLP/3_Embeddings/ejercicios/ejercicios_solucion.ipynb\"> <img src='https://colab.research.google.com/assets/colab-badge.svg' /> </a>"
      ],
      "metadata": {
        "id": "KxYVuQiI_uxO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Ejercicios clase 3"
      ],
      "metadata": {
        "id": "JGUGih8T60cr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "En este notebook vamos a utilizar embeddings GloVe preentrenados para mejorar la performance de nuestro modelo de análisis de sentimiento de la clase 2. "
      ],
      "metadata": {
        "id": "2vfB64SAOwJA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Comenzaremos por descargar los embeddings. Los autores del paper de GloVe han lanzado cuatro archivos de texto con vectores de palabras entrenados en diferentes conjuntos de datos web masivos. Están disponibles para descargar [aquí](https://nlp.stanford.edu/projects/glove/).\n",
        "\n",
        "Usaremos “Wikipedia 2014 + Gigaword 5” que es el archivo más pequeño (“glove.6B.zip”) con 822 MB. Fue entrenado en un corpus de 6 mil millones de tokens y contiene un vocabulario de 400 mil tokens.\n",
        "\n",
        "La siguiente celda descarga y descomprime el archivo."
      ],
      "metadata": {
        "id": "VIRwMd5rPoOm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://nlp.stanford.edu/data/glove.6B.zip\n",
        "!unzip glove.6B.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VrvOJHfQG8pD",
        "outputId": "d3267f29-ea51-450d-ab02-4a69647d6600"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-08-24 01:08:32--  https://nlp.stanford.edu/data/glove.6B.zip\n",
            "Resolving nlp.stanford.edu (nlp.stanford.edu)... 171.64.67.140\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: https://downloads.cs.stanford.edu/nlp/data/glove.6B.zip [following]\n",
            "--2022-08-24 01:08:33--  https://downloads.cs.stanford.edu/nlp/data/glove.6B.zip\n",
            "Resolving downloads.cs.stanford.edu (downloads.cs.stanford.edu)... 171.64.64.22\n",
            "Connecting to downloads.cs.stanford.edu (downloads.cs.stanford.edu)|171.64.64.22|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 862182613 (822M) [application/zip]\n",
            "Saving to: ‘glove.6B.zip.1’\n",
            "\n",
            "glove.6B.zip.1      100%[===================>] 822.24M  5.07MB/s    in 2m 39s  \n",
            "\n",
            "2022-08-24 01:11:13 (5.17 MB/s) - ‘glove.6B.zip.1’ saved [862182613/862182613]\n",
            "\n",
            "Archive:  glove.6B.zip\n",
            "replace glove.6B.50d.txt? [y]es, [n]o, [A]ll, [N]one, [r]ename: y\n",
            "  inflating: glove.6B.50d.txt        \n",
            "replace glove.6B.100d.txt? [y]es, [n]o, [A]ll, [N]one, [r]ename: A\n",
            "  inflating: glove.6B.100d.txt       \n",
            "  inflating: glove.6B.200d.txt       \n",
            "  inflating: glove.6B.300d.txt       \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Después de descomprimir el archivo descargado, encontramos cuatro archivos txt: glove.6B.50d.txt, glove.6B.100d.txt, glove.6B.200d.txt, glove.6B.300d.txt. Como sugiere su nombre de archivo, tienen vectores con diferentes dimensiones.\n",
        "\n",
        "Si imprimimos las primeras lineas podemos notar que cada linea contiene un embedding en donde el primer elemento es un tensor y los siguientes son las componentes del vector."
      ],
      "metadata": {
        "id": "4RbjM1OXQaLq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with open( \"glove.6B.100d.txt\", 'r') as f:\n",
        "  n_lin = 0\n",
        "  for line in f:\n",
        "    print(line)\n",
        "    n_lin += 1\n",
        "    if n_lin>3: break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eIX0QLCyQ6rv",
        "outputId": "5efbb163-bfa5-4f25-91c6-9067ac48aeb3"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "the -0.038194 -0.24487 0.72812 -0.39961 0.083172 0.043953 -0.39141 0.3344 -0.57545 0.087459 0.28787 -0.06731 0.30906 -0.26384 -0.13231 -0.20757 0.33395 -0.33848 -0.31743 -0.48336 0.1464 -0.37304 0.34577 0.052041 0.44946 -0.46971 0.02628 -0.54155 -0.15518 -0.14107 -0.039722 0.28277 0.14393 0.23464 -0.31021 0.086173 0.20397 0.52624 0.17164 -0.082378 -0.71787 -0.41531 0.20335 -0.12763 0.41367 0.55187 0.57908 -0.33477 -0.36559 -0.54857 -0.062892 0.26584 0.30205 0.99775 -0.80481 -3.0243 0.01254 -0.36942 2.2167 0.72201 -0.24978 0.92136 0.034514 0.46745 1.1079 -0.19358 -0.074575 0.23353 -0.052062 -0.22044 0.057162 -0.15806 -0.30798 -0.41625 0.37972 0.15006 -0.53212 -0.2055 -1.2526 0.071624 0.70565 0.49744 -0.42063 0.26148 -1.538 -0.30223 -0.073438 -0.28312 0.37104 -0.25217 0.016215 -0.017099 -0.38984 0.87424 -0.72569 -0.51058 -0.52028 -0.1459 0.8278 0.27062\n",
            "\n",
            ", -0.10767 0.11053 0.59812 -0.54361 0.67396 0.10663 0.038867 0.35481 0.06351 -0.094189 0.15786 -0.81665 0.14172 0.21939 0.58505 -0.52158 0.22783 -0.16642 -0.68228 0.3587 0.42568 0.19021 0.91963 0.57555 0.46185 0.42363 -0.095399 -0.42749 -0.16567 -0.056842 -0.29595 0.26037 -0.26606 -0.070404 -0.27662 0.15821 0.69825 0.43081 0.27952 -0.45437 -0.33801 -0.58184 0.22364 -0.5778 -0.26862 -0.20425 0.56394 -0.58524 -0.14365 -0.64218 0.0054697 -0.35248 0.16162 1.1796 -0.47674 -2.7553 -0.1321 -0.047729 1.0655 1.1034 -0.2208 0.18669 0.13177 0.15117 0.7131 -0.35215 0.91348 0.61783 0.70992 0.23955 -0.14571 -0.37859 -0.045959 -0.47368 0.2385 0.20536 -0.18996 0.32507 -1.1112 -0.36341 0.98679 -0.084776 -0.54008 0.11726 -1.0194 -0.24424 0.12771 0.013884 0.080374 -0.35414 0.34951 -0.7226 0.37549 0.4441 -0.99059 0.61214 -0.35111 -0.83155 0.45293 0.082577\n",
            "\n",
            ". -0.33979 0.20941 0.46348 -0.64792 -0.38377 0.038034 0.17127 0.15978 0.46619 -0.019169 0.41479 -0.34349 0.26872 0.04464 0.42131 -0.41032 0.15459 0.022239 -0.64653 0.25256 0.043136 -0.19445 0.46516 0.45651 0.68588 0.091295 0.21875 -0.70351 0.16785 -0.35079 -0.12634 0.66384 -0.2582 0.036542 -0.13605 0.40253 0.14289 0.38132 -0.12283 -0.45886 -0.25282 -0.30432 -0.11215 -0.26182 -0.22482 -0.44554 0.2991 -0.85612 -0.14503 -0.49086 0.0082973 -0.17491 0.27524 1.4401 -0.21239 -2.8435 -0.27958 -0.45722 1.6386 0.78808 -0.55262 0.65 0.086426 0.39012 1.0632 -0.35379 0.48328 0.346 0.84174 0.098707 -0.24213 -0.27053 0.045287 -0.40147 0.11395 0.0062226 0.036673 0.018518 -1.0213 -0.20806 0.64072 -0.068763 -0.58635 0.33476 -1.1432 -0.1148 -0.25091 -0.45907 -0.096819 -0.17946 -0.063351 -0.67412 -0.068895 0.53604 -0.87773 0.31802 -0.39242 -0.23394 0.47298 -0.028803\n",
            "\n",
            "of -0.1529 -0.24279 0.89837 0.16996 0.53516 0.48784 -0.58826 -0.17982 -1.3581 0.42541 0.15377 0.24215 0.13474 0.41193 0.67043 -0.56418 0.42985 -0.012183 -0.11677 0.31781 0.054177 -0.054273 0.35516 -0.30241 0.31434 -0.33846 0.71715 -0.26855 -0.15837 -0.47467 0.051581 -0.33252 0.15003 -0.1299 -0.54617 -0.37843 0.64261 0.82187 -0.080006 0.078479 -0.96976 -0.57741 0.56491 -0.39873 -0.057099 0.19743 0.065706 -0.48092 -0.20125 -0.40834 0.39456 -0.02642 -0.11838 1.012 -0.53171 -2.7474 -0.042981 -0.74849 1.7574 0.59085 0.04885 0.78267 0.38497 0.42097 0.67882 0.10337 0.6328 -0.026595 0.58647 -0.44332 0.33057 -0.12022 -0.55645 0.073611 0.20915 0.43395 -0.012761 0.089874 -1.7991 0.084808 0.77112 0.63105 -0.90685 0.60326 -1.7515 0.18596 -0.50687 -0.70203 0.66578 -0.81304 0.18712 -0.018488 -0.26757 0.727 -0.59363 -0.34839 -0.56094 -0.591 1.0039 0.20664\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Ejercicio 1 "
      ],
      "metadata": {
        "id": "jYJqUwCcRTW9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cargue los primeros 400.000 embeddings del archivo de 100 dimensiones en memoria tal como lo hicimos en la clase 3, parte 3.\n",
        "\n",
        "Nota: tener en cuenta que este archivo no tiene una primera linea de encabezados como el archivo de la clase.*texto en cursiva*"
      ],
      "metadata": {
        "id": "VSKRGcklRZF7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# inserte su código aquí\n",
        "\n",
        "import torch\n",
        "class TokenEmbedding:\n",
        "  \"\"\"Token Embedding.\"\"\"\n",
        "  def __init__(self, file_name, n):\n",
        "    self.idx_to_token, self.idx_to_vec, self.dim = self._load_embedding(\n",
        "        file_name, n)\n",
        "    self.unknown_idx = 0\n",
        "    self.token_to_idx = {token: idx for idx, token in\n",
        "                          enumerate(self.idx_to_token)}\n",
        "  \n",
        "\n",
        "  def _load_embedding(self, file_name, n):\n",
        "    idx_to_token, idx_to_vec = ['<unk>'], []\n",
        "    with open( file_name, 'r') as f:\n",
        "      i=0\n",
        "      for line in f:\n",
        "        if n<i: break\n",
        "        else: i+=1\n",
        "        elems = line.rstrip().split(' ')\n",
        "        token, elems = elems[0], [float(elem) for elem in elems[1:]]\n",
        "        # Skip header information, such as the top row in fastText\n",
        "        if len(elems) > 1:\n",
        "            idx_to_token.append(token)\n",
        "            idx_to_vec.append(elems)\n",
        "    idx_to_vec = [[0] * len(idx_to_vec[0])] + idx_to_vec\n",
        "    return idx_to_token, torch.tensor(idx_to_vec), len(idx_to_vec[0])\n",
        "\n",
        "  def __getitem__(self, tokens):\n",
        "    indices = [self.token_to_idx.get(token, self.unknown_idx)\n",
        "                for token in tokens]\n",
        "    vecs = self.idx_to_vec[torch.tensor(indices)]\n",
        "    return vecs\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.idx_to_token)\n",
        "\n",
        "english_glove_100d = TokenEmbedding(\"glove.6B.100d.txt\",400000)"
      ],
      "metadata": {
        "id": "rKJRCWAEIZOW"
      },
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Ejercicio 2\n",
        "\n",
        "Modificar el modelo `model2`, definido en los ejercicios de la clase 2 para análisis de sentimientos, para que la capa de embedding se inicialice con los embeddings GloVe preentrenados que descargamos.\n",
        "\n",
        "Nota: Recuerde que la matriz de embeddings depende del vocabulario a usar en el problema. Por lo tanto, deberá realizar todo el preprocesamiento de los datos, para obtener el vocabulario, antes de modificar el modelo. "
      ],
      "metadata": {
        "id": "qlrAmc7uSZSf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# inserte su código a partir de aquí"
      ],
      "metadata": {
        "id": "ek-bMGgnToY1"
      },
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "################################ Setup\n",
        "import torch\n",
        "import torchtext\n",
        "\n",
        "SEED = 1234\n",
        "\n",
        "torch.manual_seed(SEED)\n",
        "torch.backends.cudnn.deterministic = True\n",
        "!pip install torchdata"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u8Ow3jIZIas5",
        "outputId": "f7e74f4f-ec22-4492-e5a5-a54945cfdfb5"
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: torchdata in /usr/local/lib/python3.7/dist-packages (0.4.1)\n",
            "Requirement already satisfied: torch==1.12.1 in /usr/local/lib/python3.7/dist-packages (from torchdata) (1.12.1+cu113)\n",
            "Requirement already satisfied: urllib3>=1.25 in /usr/local/lib/python3.7/dist-packages (from torchdata) (1.25.11)\n",
            "Requirement already satisfied: portalocker>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from torchdata) (2.5.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from torchdata) (2.23.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch==1.12.1->torchdata) (4.1.1)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->torchdata) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->torchdata) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->torchdata) (2022.6.15)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "myUGQPJGFyhw"
      },
      "source": [
        "################################ Preprocesamos los datos\n",
        "import torchdata\n",
        "import random\n",
        "from torchtext.datasets import IMDB\n",
        "from torchtext.data.utils import get_tokenizer\n",
        "from collections import Counter\n",
        "from torchtext.vocab import vocab\n",
        "\n",
        "train_data, test_data = IMDB(split=('train', 'test'))\n",
        "\n",
        "# guardaremos momentaneamente los datos en listas.\n",
        "full_list = list(train_data)\n",
        "cutoff = int(len(full_list) * 0.7)\n",
        "\n",
        "random.seed(SEED)\n",
        "random.shuffle(full_list)\n",
        "\n",
        "train_list = full_list[:cutoff] # entrenamiento\n",
        "val_list = full_list[cutoff:] # validacion\n",
        "test_list = list(test_data) # prueba\n",
        "\n",
        "#Generamos el vocabulario\n",
        "tokenizer = get_tokenizer('spacy', 'en_core_web_sm')\n",
        "counter = Counter()\n",
        "for (label, line) in train_list: \n",
        "    counter.update(tokenizer(line)) #contador como el visto en clase\n",
        "vocab = vocab(counter, min_freq=10, # eliminamos todo menor a 10 repeciones\n",
        "              specials=('<unk>', '<PAD>'))\n",
        "vocab.set_default_index(vocab['<unk>'])\n"
      ],
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "################################ Modificamos el modelo\n",
        "import numpy as np\n",
        "import torch.nn as nn\n",
        "\n",
        "#Generamos la matriz de pesos a partir del vocabulario con los embeddings GloVe\n",
        "matrix_len = len(vocab.get_itos())\n",
        "weights_matrix = np.zeros((len(vocab.get_itos()), english_glove_100d.dim))\n",
        "words_found = 0\n",
        "words_not_found = []\n",
        "\n",
        "for i, word in enumerate(vocab.get_itos()):\n",
        "    try: \n",
        "        weights_matrix[i] = english_glove_100d[[word]][0]\n",
        "        words_found += 1\n",
        "    except KeyError:\n",
        "        weights_matrix[i] = np.random.normal(scale=0.6, size=(english_glove_100d.dim, ))\n",
        "        words_not_found.append(word)\n",
        "\n",
        "#Definimos la función que crea la capa Embedding con la matriz de pesos\n",
        "def create_emb_layer(weights_matrix, non_trainable=False):\n",
        "    num_embeddings, embedding_dim = weights_matrix.shape\n",
        "    emb_layer = nn.Embedding(num_embeddings, embedding_dim)\n",
        "    emb_layer.load_state_dict({'weight': torch.tensor(weights_matrix)})\n",
        "    if non_trainable:\n",
        "        emb_layer.weight.requires_grad = False\n",
        "\n",
        "    return emb_layer, num_embeddings, embedding_dim\n",
        "\n",
        "#Modificamos el modelo para inicializar la capa Embedding\n",
        "class RNN(nn.Module):\n",
        "    def __init__(self, input_dim, weights_matrix, pad_index,\n",
        "                 hidden_dim, output_dim, num_layers, bidirectional, dropout):\n",
        "        \n",
        "        super().__init__()\n",
        "\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "        ###### inicio modificación #######\n",
        "        self.embedding, num_embeddings, embedding_dim = create_emb_layer(weights_matrix,\n",
        "                                                                         True)\n",
        "        ###### fin modificación #######\n",
        "            \n",
        "        self.rnn = nn.GRU(embedding_dim, hidden_dim, num_layers,\n",
        "                          bidirectional = bidirectional, dropout=dropout)\n",
        "\n",
        "        self.num_layers = num_layers\n",
        "        self.bidirectional = bidirectional        \n",
        "        if bidirectional:\n",
        "          hidden_dim *= 2\n",
        "        self.linear = nn.Linear(hidden_dim * num_layers, output_dim)\n",
        "\n",
        "        \n",
        "    def forward(self, text, text_lengths):\n",
        "\n",
        "        #text = [sent len, batch size]\n",
        "        \n",
        "        embedded = self.dropout(self.embedding(text))\n",
        "        packed_embedded = nn.utils.rnn.pack_padded_sequence(embedded, text_lengths.to('cpu'))\n",
        "        \n",
        "        #embedded = [sent len, batch size, emb dim]\n",
        "        \n",
        "        packed_output, hidden = self.rnn(packed_embedded)\n",
        "        \n",
        "        #output = [sent len, batch size, hid dim]\n",
        "        #hidden = [2 * 2, batch size, hid dim]\n",
        "        chunks = self.num_layers\n",
        "        if self.bidirectional: chunks *= 2\n",
        "        dropped_h = self.dropout(\n",
        "            torch.cat(torch.chunk(hidden,chunks,0), dim=2).squeeze(0))\n",
        "        return self.linear(dropped_h)\n",
        "\n",
        "\n",
        "# Instanciamos el modelo definido\n",
        "INPUT_DIM = len(vocab)\n",
        "PAD_IDX = vocab['<PAD>']\n",
        "HIDDEN_DIM = 256\n",
        "NUM_LAYERS = 2\n",
        "BIDIRECTIONAL = True\n",
        "OUTPUT_DIM = 1\n",
        "DROPOUT = 0.5\n",
        "\n",
        "model2 = RNN(INPUT_DIM, weights_matrix, PAD_IDX,\n",
        "            HIDDEN_DIM,OUTPUT_DIM, NUM_LAYERS, BIDIRECTIONAL, DROPOUT)\n",
        "\n",
        "def count_parameters(model):\n",
        "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "\n",
        "print(f'El modelo tiene {count_parameters(model2):,} parámetros entrenables')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HPIIcyIaURid",
        "outputId": "cec4f426-47a0-4411-8078-aec44b6aeaf6"
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "El modelo tiene 1,733,633 parámetros entrenables\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Ejercicio 3 \n",
        "Entrene este nuevo modelo y compare los resultados obtenidos.\n",
        "\n",
        "Nota: Reutilice todo el código de los ejercicios de la clase 2"
      ],
      "metadata": {
        "id": "oNumMc36Vnlc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# inserte su código a partir de aquí"
      ],
      "metadata": {
        "id": "maynQ5U3VmxX"
      },
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "####################### Creación de Dataloaders\n",
        "\n",
        "\n",
        "import random\n",
        "from torch.utils.data.sampler import Sampler\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "\n",
        "class BucketSampler(Sampler):\n",
        "\n",
        "    def __init__(self, batch_size, train_list):\n",
        "        self.length = len(train_list)\n",
        "        self.train_list = train_list\n",
        "        self.batch_size = batch_size\n",
        "        indices = [(i, len(tokenizer(s[1]))) for i, s in enumerate(self.train_list)]\n",
        "        random.seed(SEED)\n",
        "        random.shuffle(indices)\n",
        "        pooled_indices = []\n",
        "        # creamos minilotes de tamaños similares\n",
        "        for i in range(0, len(indices), self.batch_size * 100):\n",
        "            pooled_indices.extend(sorted(indices[i:i + self.batch_size * 100], key=lambda x: x[1], reverse=True))\n",
        "\n",
        "        self.pooled_indices = pooled_indices\n",
        "\n",
        "    def __iter__(self):\n",
        "        for i in range(0, len(self.pooled_indices), self.batch_size):\n",
        "            yield [idx for idx, _ in self.pooled_indices[i:i + self.batch_size]]\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.length\n",
        "        return (self.length + self.batch_size - 1) // self.batch_size\n",
        "\n",
        "text_transform = lambda x: [vocab[token] for token in tokenizer(x)]\n",
        "label_transform = lambda x: 1 if x == 'pos' else 0\n",
        "\n",
        "def collate_batch(batch):\n",
        "    label_list, text_list, length_list = [], [], []\n",
        "    for (_label, _text) in batch:\n",
        "        # convertimos la etiqueta usando label_transform\n",
        "        label_list.append(label_transform(_label))\n",
        "        # convertimos el texto en tokens\n",
        "        processed_text = torch.tensor(text_transform(_text))\n",
        "        text_list.append(processed_text)\n",
        "        # guardamos la longitud de cada token\n",
        "        length_list.append(len(processed_text))\n",
        "    # armamos la tupla que conformara un ejemplo de minilote.\n",
        "    result = (torch.tensor(label_list),\n",
        "              pad_sequence(text_list, padding_value=1.0),\n",
        "              torch.tensor(length_list) )\n",
        "    return result\n",
        "\n",
        "batch_size = 64  # A batch size of 64\n",
        "\n",
        "train_bucket = BucketSampler(batch_size, train_list)\n",
        "train_iter = DataLoader(train_list,\n",
        "                          batch_sampler=train_bucket,\n",
        "                          collate_fn=collate_batch)\n",
        "\n",
        "val_bucket = BucketSampler(batch_size, val_list)\n",
        "val_iter = DataLoader(val_list,\n",
        "                          batch_sampler=val_bucket,\n",
        "                          collate_fn=collate_batch)\n",
        "\n",
        "test_bucket = BucketSampler(batch_size, test_list)\n",
        "test_iter = DataLoader(test_list,\n",
        "                          batch_sampler=test_bucket,\n",
        "                          collate_fn=collate_batch)\n"
      ],
      "metadata": {
        "id": "njqYBX5CGdn0"
      },
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jtal3fh7Tsp4"
      },
      "source": [
        "###################### Preparación del entrenamiento\n",
        "import torch.optim as optim\n",
        "import time\n",
        "\n",
        "optimizer2 = optim.Adam(model2.parameters())\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "model2 = model2.to(device)\n",
        "loss = nn.BCEWithLogitsLoss().to(device)\n",
        "\n",
        "def binary_accuracy(preds, y):\n",
        "    rounded_preds = torch.round(torch.sigmoid(preds))\n",
        "    correct = (rounded_preds == y).float() #convertimos a flotante para la división\n",
        "    acc = correct.sum() / len(correct)\n",
        "    return acc\n",
        "\n",
        "def epoch_time(start_time, end_time):\n",
        "    elapsed_time = end_time - start_time\n",
        "    elapsed_mins = int(elapsed_time / 60)\n",
        "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
        "    return elapsed_mins, elapsed_secs\n",
        "\n",
        "def train_epoch_wl(model, iterator, optimizer, criterion, device):\n",
        "    epoch_loss = 0\n",
        "    epoch_acc = 0\n",
        "    model.train()\n",
        "    stop = 0\n",
        "    for label, text, length in iterator:\n",
        "        label = label.float().to(device)\n",
        "        text = text.to(device)\n",
        "        optimizer.zero_grad()       \n",
        "        predictions = model(text, length).squeeze(1)\n",
        "        loss = criterion(predictions, label)\n",
        "        acc = binary_accuracy(predictions, label)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        epoch_loss += loss.item()\n",
        "        epoch_acc += acc.item()\n",
        "    return epoch_loss * batch_size / len(iterator), epoch_acc * batch_size / len(iterator) \n",
        "\n",
        "def evaluate_epoch_wl(model, iterator, criterion, device):\n",
        "    epoch_loss = 0\n",
        "    epoch_acc = 0\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        stop = 0\n",
        "        for label, text, length in iterator:          \n",
        "            label = label.float().to(device)\n",
        "            text = text.to(device)\n",
        "            predictions = model(text, length).squeeze(1)            \n",
        "            loss = criterion(predictions, label)            \n",
        "            acc = binary_accuracy(predictions, label)\n",
        "            epoch_loss += loss.item()\n",
        "            epoch_acc += acc.item()        \n",
        "    return epoch_loss * batch_size / len(iterator), epoch_acc * batch_size / len(iterator) "
      ],
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dA5t4ufnTsqE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7e199e5d-bdee-4009-a79f-548893d34eb1"
      },
      "source": [
        "################### Entrenamiento\n",
        "N_EPOCHS = 10\n",
        "\n",
        "for epoch in range(N_EPOCHS):\n",
        "\n",
        "    start_time = time.time()\n",
        "    \n",
        "    train_loss, train_acc = train_epoch_wl(model2, train_iter,\n",
        "                                        optimizer2, loss, device)\n",
        "    valid_loss, valid_acc = evaluate_epoch_wl(model2, val_iter, loss, device)\n",
        "    \n",
        "    end_time = time.time()\n",
        "\n",
        "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
        "        \n",
        "    print(f'Epoch: {epoch+1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s')\n",
        "    print(f'\\tTrain Loss: {train_loss:.3f} | Train Acc: {train_acc*100:.2f}%')\n",
        "    print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. Acc: {valid_acc*100:.2f}%')"
      ],
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 01 | Epoch Time: 0m 38s\n",
            "\tTrain Loss: 0.621 | Train Acc: 64.56%\n",
            "\t Val. Loss: 0.468 |  Val. Acc: 79.20%\n",
            "Epoch: 02 | Epoch Time: 0m 42s\n",
            "\tTrain Loss: 0.437 | Train Acc: 80.19%\n",
            "\t Val. Loss: 0.520 |  Val. Acc: 76.76%\n",
            "Epoch: 03 | Epoch Time: 0m 39s\n",
            "\tTrain Loss: 0.408 | Train Acc: 81.98%\n",
            "\t Val. Loss: 0.483 |  Val. Acc: 79.94%\n",
            "Epoch: 04 | Epoch Time: 0m 40s\n",
            "\tTrain Loss: 0.383 | Train Acc: 83.12%\n",
            "\t Val. Loss: 0.374 |  Val. Acc: 84.60%\n",
            "Epoch: 05 | Epoch Time: 0m 39s\n",
            "\tTrain Loss: 0.367 | Train Acc: 84.10%\n",
            "\t Val. Loss: 0.394 |  Val. Acc: 83.20%\n",
            "Epoch: 06 | Epoch Time: 0m 39s\n",
            "\tTrain Loss: 0.356 | Train Acc: 84.57%\n",
            "\t Val. Loss: 0.316 |  Val. Acc: 86.87%\n",
            "Epoch: 07 | Epoch Time: 0m 39s\n",
            "\tTrain Loss: 0.335 | Train Acc: 85.87%\n",
            "\t Val. Loss: 0.319 |  Val. Acc: 87.25%\n",
            "Epoch: 08 | Epoch Time: 0m 39s\n",
            "\tTrain Loss: 0.327 | Train Acc: 86.08%\n",
            "\t Val. Loss: 0.286 |  Val. Acc: 88.54%\n",
            "Epoch: 09 | Epoch Time: 0m 39s\n",
            "\tTrain Loss: 0.311 | Train Acc: 86.87%\n",
            "\t Val. Loss: 0.289 |  Val. Acc: 88.24%\n",
            "Epoch: 10 | Epoch Time: 0m 39s\n",
            "\tTrain Loss: 0.293 | Train Acc: 87.78%\n",
            "\t Val. Loss: 0.284 |  Val. Acc: 88.90%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r1c1II3cTsqE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7c584f00-647b-4217-e878-fdf5823cb558"
      },
      "source": [
        "####################### Evaluación\n",
        "test_loss, test_acc = evaluate_epoch_wl(model2, test_iter, loss, device)\n",
        "\n",
        "print(f'Test Loss: {test_loss:.3f} | Test Acc: {test_acc*100:.2f}%')"
      ],
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Loss: 0.289 | Test Acc: 88.04%\n"
          ]
        }
      ]
    }
  ]
}