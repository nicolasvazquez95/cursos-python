{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled0.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "<a href=\"https://colab.research.google.com/github/institutohumai/cursos-python/blob/master/DeepLearning/5_Evaluacion_Modelos/ejercicios/ejercicios_solucion.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open in Colab\"/></a>"
      ],
      "metadata": {
        "id": "XNndA7oHay2t"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Ejercicios de la clase 5"
      ],
      "metadata": {
        "id": "Cf1-htxCJLPQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Para llevar adelante los ejercicios de este notebook vamos a recuperar los modelos que construimos en la clase 3 para clasificación sobre FashionMNIST."
      ],
      "metadata": {
        "id": "kJIVioMJJUOf"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "wVO-ycjBBvnY"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "\n",
        "INPUT = 28 * 28 \n",
        "OUTPUT = 10 \n",
        "\n",
        "net1 = nn.Sequential(nn.Flatten(),\n",
        "                    nn.Linear(INPUT, 512),\n",
        "                    nn.ReLU(),\n",
        "                    nn.Linear(512, 128),\n",
        "                    nn.ReLU(),\n",
        "                    nn.Linear(128, OUTPUT))\n",
        "\n",
        "net2 = nn.Sequential(nn.Flatten(),\n",
        "                    nn.Linear(INPUT, 512),\n",
        "                    nn.Sigmoid(),\n",
        "                    nn.Linear(512, 128),\n",
        "                    nn.Sigmoid(),\n",
        "                    nn.Linear(128, OUTPUT))\n",
        "\n",
        "net3 = nn.Sequential(nn.Flatten(),\n",
        "                    nn.Linear(INPUT, 1024),\n",
        "                    nn.ReLU(),\n",
        "                    nn.Linear(1024, 1024),\n",
        "                    nn.ReLU(),\n",
        "                    nn.Linear(1024, OUTPUT))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ahora repetiremos la evaluación que hicimos en esa clase, pero llevándola adelante de manera más exhaustiva con K-fold Cross Validation. Para eso, cargaremos solo los datos de testeo de FasionMNIST y fingiremos que esos 10000 ejemplos son todos los que tenemos."
      ],
      "metadata": {
        "id": "bQNVbp8DJk4P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision import transforms, datasets\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "data_iter = datasets.FashionMNIST(\n",
        "        root=\"../data\", train=False, transform=transforms.ToTensor(), download=True)"
      ],
      "metadata": {
        "id": "6ytpnrsdBxnm"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Ejercicio \n",
        "Verifique cuál de los modelos anteriores es el mejor llevando adelante proceso de cross validation con 3 folds y entrenando por 20 epochs. Reutilice todas las funciones que necesite de los notebooks de teoría de la clase 5 y de todos los ejercicios anteriores.\n",
        "\n",
        "Nota: le recomendamos que guarde las accuracy tanto de testeo como de entrenamiento porque le servirán para más adelante."
      ],
      "metadata": {
        "id": "57in9CJhKirI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#### Funciones necesarias de otros notebooks\n",
        "\n",
        "def reset_weights(m):\n",
        "  if type(m) == nn.Linear:\n",
        "      nn.init.normal_(m.weight, std=0.01)\n",
        "\n",
        "def accuracy(y_hat, y):\n",
        "    \"\"\"Compute the number of correct predictions.\"\"\"\n",
        "    if len(y_hat.shape) > 1 and y_hat.shape[1] > 1:\n",
        "        y_hat = y_hat.argmax(axis=1)\n",
        "    cmp = y_hat.type(y.dtype) == y\n",
        "    return float(cmp.type(y.dtype).sum())\n",
        "\n",
        "    \n",
        "def test_accuracy(fold,model, loss, device, test_loader):\n",
        "  # inserte su código aquí\n",
        "  TestAcc = 0.0\n",
        "  N = 0\n",
        "  for X, y in test_loader:\n",
        "      X, y = X.to(device), y.to(device)\n",
        "      N += y.numel()\n",
        "      TestAcc += accuracy(model(X), y)\n",
        "  print('\\nTest set for fold {}:  Accuracy: {}/{} ({:.0f}%)'.format(\n",
        "        fold, TestAcc, N,\n",
        "        (100. * TestAcc) / N))\n",
        "  return TestAcc / N\n",
        "\n",
        "def train_accuracy(fold,model, loss, device, test_loader):\n",
        "  # inserte su código aquí\n",
        "  TestAcc = 0.0\n",
        "  N = 0\n",
        "  for X, y in test_loader:\n",
        "      X, y = X.to(device), y.to(device)\n",
        "      N += y.numel()\n",
        "      TestAcc += accuracy(model(X), y)\n",
        "  print('\\nTrain set for fold {}:  Accuracy: {}/{} ({:.0f}%)'.format(\n",
        "        fold, TestAcc, N,\n",
        "        (100. * TestAcc) / N))\n",
        "  return TestAcc / N\n",
        "\n",
        "def train(fold, model, device, loss, train_loader, optimizer, epoch):\n",
        "\n",
        "  for batch_idx, (data, target) in enumerate(train_loader):\n",
        "      data, target = data.to(device), target.to(device)\n",
        "      optimizer.zero_grad()\n",
        "      l = loss(model(data), target).mean()\n",
        "      l.backward()\n",
        "      optimizer.step()"
      ],
      "metadata": {
        "id": "F64LA0m3CIWd"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import KFold\n",
        "\n",
        "### Función que lleva adelante el proceso de kfold cross validation\n",
        "def train_kfold(model, dataset, n_fold, epochs):\n",
        "  device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "  loss = torch.nn.CrossEntropyLoss(reduction='none')\n",
        "  optimizer = torch.optim.Adam(model.parameters())\n",
        "  batch_size=32\n",
        "  folds=n_fold\n",
        "  train_acc = []\n",
        "  acc = []\n",
        "  kfold=KFold(n_splits=n_fold,shuffle=True)\n",
        "  for fold,(train_idx,test_idx) in enumerate(kfold.split(dataset)):\n",
        "    print('------------fold no---------{}----------------------'.format(fold))\n",
        "    train_subsampler = torch.utils.data.SubsetRandomSampler(train_idx)\n",
        "    test_subsampler = torch.utils.data.SubsetRandomSampler(test_idx)\n",
        "\n",
        "    trainloader = torch.utils.data.DataLoader(\n",
        "                        dataset, \n",
        "                        batch_size=batch_size, sampler=train_subsampler)\n",
        "    testloader = torch.utils.data.DataLoader(\n",
        "                        dataset,\n",
        "                        batch_size=batch_size, sampler=test_subsampler)\n",
        "\n",
        "    model.apply(reset_weights)\n",
        "\n",
        "    fold_acc = 0\n",
        "    for epoch in range(1, epochs + 1):\n",
        "      train(fold, model, device, loss, trainloader, optimizer, epoch)\n",
        "      fold_train_acc = train_accuracy(fold,model, loss, device, trainloader)\n",
        "      fold_acc = test_accuracy(fold,model, loss, device,  testloader)\n",
        "    train_acc.append(fold_train_acc)\n",
        "    acc.append(fold_acc)\n",
        "  return train_acc, acc"
      ],
      "metadata": {
        "id": "I6UgC0b3ClEk"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "##### Lleva adelante los entrenamientos\n",
        "train_acc1, acc_1 = train_kfold(net1, data_iter, 3, 20)\n",
        "train_acc2, acc_2 = train_kfold(net2, data_iter, 3, 20)\n",
        "train_acc3, acc_3 = train_kfold(net3, data_iter, 3, 20)\n"
      ],
      "metadata": {
        "id": "YuNp2K1vEW79"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "print(\"Modelo 1:  entrenamiento \", np.array(train_acc1).mean(), \", validación: \", np.array(acc_1).mean() )\n",
        "print(\"Modelo 2:  entrenamiento \", np.array(train_acc2).mean(), \", validación: \", np.array(acc_2).mean() )\n",
        "print(\"Modelo 3:  entrenamiento \", np.array(train_acc3).mean(), \", validación: \", np.array(acc_3).mean() )\n"
      ],
      "metadata": {
        "id": "cS5Ig9ARTgYq",
        "outputId": "98117611-069c-4c35-c36e-e852eb409a85",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Modelo 1:  entrenamiento  0.9299502546624844 , validación:  0.8491994370402848\n",
            "Modelo 2:  entrenamiento  0.91875006459698 , validación:  0.8403005267533352\n",
            "Modelo 3:  entrenamiento  0.9470998847297359 , validación:  0.8509007169463197\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Modelo 3:  entrenamiento \", np.array(train_acc3).mean(), \", validación: \", np.array(acc_3).mean() )"
      ],
      "metadata": {
        "id": "ywuqHeI1Y4SE",
        "outputId": "7d5672b4-8d54-4690-e154-df4ebb965d25",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Modelo 3:  entrenamiento  0.8948503519918513 , validación:  0.8312986067652957\n"
          ]
        }
      ]
    }
  ]
}